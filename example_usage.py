#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ูุซุงู ุงุณุชูุงุฏู ุงุฒ ุณุณุชู ุฌุณุชุฌู FHE
===================================

ุงู ูุงู ูุญูู ุงุณุชูุงุฏู ุงุฒ ุณุณุชู ุฌุณุชุฌู ุฑูุฒูฺฏุงุฑ ููููุฑูฺฉ ุฑุง ูุดุงู ูโุฏูุฏ.
"""

from fhe_search import FHESearchEngine
import json
import time

def load_sample_documents():
    """ุจุงุฑฺฏุฐุงุฑ ุงุณูุงุฏ ููููู"""
    documents = [
        # ุงุณูุงุฏ ูุงุฑุณ
        "ููุด ูุตููุน ู ุงุฏฺฏุฑ ูุงุดู ุฏุฑ ุญุงู ุชุบุฑ ุฏูุง ููุงูุฑ ูุณุชูุฏ.",
        "ุงููุช ุณุงุจุฑ ู ุญูุงุธุช ุงุฒ ุฏุงุฏูโูุง ุฏุฑ ุนุตุฑ ุฏุฌุชุงู ุงููุช ุจุงูุง ุฏุงุฑุฏ.",
        "ุฑูุฒูฺฏุงุฑ ฺฉูุงูุชูู ุขูุฏู ุงููุช ุงุทูุงุนุงุช ุฑุง ูุชุญูู ุฎูุงูุฏ ฺฉุฑุฏ.",
        "ูพุฑุฏุงุฒุด ุฒุจุงู ุทุจุน ุจู ฺฉุงููพูุชุฑูุง ฺฉูฺฉ ูโฺฉูุฏ ุชุง ุงูุณุงูโูุง ุฑุง ุจูุชุฑ ุฏุฑฺฉ ฺฉููุฏ.",
        "ุงูุชุฑูุช ุงุดุงุก ู ุดูุฑูุง ููุดููุฏ ุฒูุฏฺฏ ูุง ุฑุง ุชุณูู ูโฺฉููุฏ.",
        "ุจูุงฺฉฺู ู ุงุฑุฒูุง ุฏุฌุชุงู ุณุณุชู ูุงู ุฌูุงู ุฑุง ุฏฺฏุฑฺฏูู ูโฺฉููุฏ.",
        "ูุงูุนุช ูุฌุงุฒ ู ูุงูุนุช ุงูุฒูุฏู ุชุฌุฑุจูโูุง ุฌุฏุฏ ุฎูู ูโฺฉููุฏ.",
        "ูุญุงุณุจุงุช ุงุจุฑ ู edge computing ูุฑฺฉุฒ ุซูู ูพุฑุฏุงุฒุด ุฑุง ุชุบุฑ ูโุฏููุฏ.",
        
        # ุงุณูุงุฏ ุงูฺฏูุณ
        "Artificial intelligence is transforming healthcare through predictive analytics.",
        "Machine learning algorithms help in fraud detection and financial security.",
        "Deep learning models are revolutionizing computer vision applications.",
        "Natural language processing enables better human-computer interaction.",
        "Quantum computing promises to solve complex optimization problems.",
        "Blockchain technology ensures transparency in supply chain management.",
        "Cloud computing provides scalable infrastructure for modern applications.",
        "Internet of Things connects billions of devices worldwide.",
        
        # ุงุณูุงุฏ ูุฎุชูุท
        "ุงุณุชูุงุฏู ุงุฒ AI ุฏุฑ ูพุฒุดฺฉ ุจุฑุง ุชุดุฎุต ุจูุงุฑโูุง ฺฉุงุฑุจุฑุฏ ูุฑุงูุงู ุฏุงุฑุฏ.",
        "Machine learning ุฏุฑ ุชุญูู ุฏุงุฏูโูุง ูุงู ููุด ููู ุงูุง ูโฺฉูุฏ.",
        "Cybersecurity ู ุงููุช ุณุงุจุฑ ุฏู ุฑู ฺฉ ุณฺฉู ูุณุชูุฏ.",
        "ุงุณุชูุงุฏู ุงุฒ blockchain ุฏุฑ smart contracts ุงูููุงุจ ุงุฌุงุฏ ฺฉุฑุฏู ุงุณุช."
    ]
    
    # ูุชุงุฏุชุง ููููู
    metadata = []
    for i, doc in enumerate(documents):
        meta = {
            "document_id": f"doc_{i+1:03d}",
            "category": "technology" if i < 16 else "mixed",
            "source": "sample_data",
            "priority": "high" if "ุงููุช" in doc or "security" in doc.lower() else "medium"
        }
        metadata.append(meta)
    
    return documents, metadata

def demonstrate_basic_usage():
    """ููุงุด ุงุณุชูุงุฏู ูพุงู ุงุฒ ุณุณุชู"""
    print("๐ ุฑุงูโุงูุฏุงุฒ ุณุณุชู ุฌุณุชุฌู FHE...")
    
    # ุงุฌุงุฏ ููููู ุณุณุชู
    engine = FHESearchEngine(config_file='config.json')
    
    # ุจุงุฑฺฏุฐุงุฑ ุงุณูุงุฏ ููููู
    documents, metadata = load_sample_documents()
    
    print(f"๐ ุงูุฒูุฏู {len(documents)} ุณูุฏ ุจู ุณุณุชู...")
    start_time = time.time()
    
    # ุงูุฒูุฏู ุงุณูุงุฏ
    result = engine.add_documents(documents, metadata)
    
    processing_time = time.time() - start_time
    
    if result['status'] == 'success':
        print(f"โ ูพุฑุฏุงุฒุด ูููู ุฏุฑ {processing_time:.2f} ุซุงูู")
        print(f"   โข ุงุณูุงุฏ ูพุฑุฏุงุฒุด ุดุฏู: {result['processed_documents']}")
        print(f"   โข ุงุณูุงุฏ ุฑูุฒูฺฏุงุฑ ุดุฏู: {result['encrypted_documents']}")
        print(f"   โข ุชูุฒุน ุฒุจุงูโูุง: {result['language_distribution']}")
        print(f"   โข ุงูุฏุงุฒู ูุงฺฺฏุงู: {result['vocabulary_size']}")
        if result['clustering_info']:
            print(f"   โข ุชุนุฏุงุฏ ุฎูุดูโูุง: {len(result['clustering_info'])}")
    else:
        print(f"โ ุฎุทุง ุฏุฑ ูพุฑุฏุงุฒุด: {result['message']}")
        return
    
    print("\n" + "="*60)
    
    # ุชุณุช ุฌุณุชุฌููุง ูุฎุชูู
    test_queries = [
        ("ุงุฏฺฏุฑ ูุงุดู", "ูุงุฑุณ"),
        ("ุงููุช ุณุงุจุฑ", "ูุงุฑุณ"),
        ("artificial intelligence", "ุงูฺฏูุณ"),
        ("blockchain technology", "ุงูฺฏูุณ"),
        ("ููุด ูุตููุน ู AI", "ูุฎุชูุท"),
        ("quantum computing", "ุงูฺฏูุณ")
    ]
    
    print("๐ ุขุฒูุงุด ุฌุณุชุฌููุง ูุฎุชูู:\n")
    
    for query, lang_type in test_queries:
        print(f"ุฌุณุชุฌู ุจุฑุง: '{query}' ({lang_type})")
        
        search_start = time.time()
        search_result = engine.search(query, top_k=3)
        search_time = time.time() - search_start
        
        if search_result['status'] == 'success':
            print(f"โฑ๏ธ  ุฒูุงู ุฌุณุชุฌู: {search_time:.3f} ุซุงูู")
            print(f"๐ ุฒุจุงู ุชุดุฎุต ุฏุงุฏู ุดุฏู: {search_result['query_language']}")
            print(f"๐ ุชุนุฏุงุฏ ูุชุงุฌ: {search_result['returned_count']}")
            
            if search_result['results']:
                print("๐ฏ ุจูุชุฑู ูุชุงุฌ:")
                for i, result in enumerate(search_result['results'], 1):
                    score = result['similarity_score']
                    text = result['metadata']['original_text'][:80]
                    doc_lang = result['metadata']['language']
                    
                    print(f"   {i}. ุงูุชุงุฒ: {score:.3f} | ุฒุจุงู: {doc_lang}")
                    print(f"      ูุชู: {text}...")
            else:
                print("   ูฺ ูุชุฌูโุง ุงูุช ูุดุฏ")
        else:
            print(f"โ ุฎุทุง: {search_result['message']}")
        
        print("-" * 50)

def demonstrate_advanced_features():
    """ููุงุด ูฺฺฏโูุง ูพุดุฑูุชู"""
    print("\n๐ ุขุฒูุงุด ูฺฺฏโูุง ูพุดุฑูุชู:\n")
    
    engine = FHESearchEngine(config_file='config.json')
    documents, metadata = load_sample_documents()
    engine.add_documents(documents, metadata)
    
    # 1. ุฌุณุชุฌู ุจุง ููุชุฑ
    print("1๏ธโฃ ุฌุณุชุฌู ุจุง ููุชุฑ ุฒุจุงู:")
    result = engine.search(
        "technology", 
        top_k=5, 
        filters={'language': 'english'}
    )
    print(f"   ูุชุงุฌ ููุท ุงูฺฏูุณ: {result['returned_count']}")
    
    # 2. ุฌุณุชุฌู ุจุง ููุชุฑ ุฎูุดู
    print("\n2๏ธโฃ ุฌุณุชุฌู ุฏุฑ ุฎูุดู ุฎุงุต:")
    result = engine.search(
        "ููุด ูุตููุน", 
        top_k=3, 
        filters={'cluster_id': 0}
    )
    print(f"   ูุชุงุฌ ุฏุฑ ุฎูุดู 0: {result['returned_count']}")
    
    # 3. ููุงุด ูุถุนุช ุณุณุชู
    print("\n3๏ธโฃ ูุถุนุช ฺฉุงูู ุณุณุชู:")
    status = engine.get_system_status()
    
    print(f"   ๐ ุชุนุฏุงุฏ ฺฉู ุงุณูุงุฏ: {status['system_info']['total_documents']}")
    print(f"   ๐ ุงูุฏุงุฒู ูุงฺฺฏุงู: {status['system_info']['vocabulary_size']}")
    print(f"   ๐ ุขูุงุฑ ุฑูุฒูฺฏุงุฑ: {status['encryption_statistics']['success_rate']:.1%} ูููู")
    
    if status['performance_metrics']:
        perf = status['performance_metrics']
        print(f"   โก ูุงูฺฏู ุฒูุงู ุฌุณุชุฌู: {perf['avg_search_time']:.3f} ุซุงูู")
        print(f"   ๐ ูุงูฺฏู ุงูุชุงุฒ ุดุจุงูุช: {perf['avg_similarity_score']:.3f}")
    
    # 4. ุชุญูู ุฎูุดูโูุง
    if status['cluster_analysis']:
        print("\n4๏ธโฃ ุชุญูู ุฎูุดูโูุง:")
        for cluster_id, info in status['cluster_analysis'].items():
            print(f"   ุฎูุดู {cluster_id}: {info['document_count']} ุณูุฏ")
            if info['common_words']:
                common = [word for word, count in info['common_words'][:3]]
                print(f"      ฺฉููุงุช ูุดุชุฑฺฉ: {', '.join(common)}")
    
    # 5. ุตุงุฏุฑุงุช ุฏุงุฏูโูุง
    print("\n5๏ธโฃ ุตุงุฏุฑุงุช ุฏุงุฏูโูุง ุณุณุชู:")
    export_result = engine.export_system_data("system_backup", include_vectors=False)
    if export_result['status'] == 'success':
        print(f"   โ ุฏุงุฏูโูุง ุฏุฑ {export_result['filepath']} ุฐุฎุฑู ุดุฏ")

def performance_benchmark():
    """ุขุฒูุงุด ุนููฺฉุฑุฏ ุณุณุชู"""
    print("\nโก ุขุฒูุงุด ุนููฺฉุฑุฏ:\n")
    
    engine = FHESearchEngine()
    
    # ุงุฌุงุฏ ูุฌููุนู ุฏุงุฏู ุจุฒุฑฺฏโุชุฑ
    base_docs, base_meta = load_sample_documents()
    
    # ุชฺฉุซุฑ ุงุณูุงุฏ ุจุฑุง ุชุณุช ุนููฺฉุฑุฏ
    large_docs = []
    large_meta = []
    
    for i in range(5):  # 5 ุจุงุฑ ุชฺฉุฑุงุฑ = 120 ุณูุฏ
        for j, (doc, meta) in enumerate(zip(base_docs, base_meta)):
            new_doc = f"{doc} (ูุณุฎู {i+1})"
            new_meta = {**meta, "document_id": f"doc_{i}_{j}", "version": i+1}
            large_docs.append(new_doc)
            large_meta.append(new_meta)
    
    print(f"๐ ุขุฒูุงุด ุจุง {len(large_docs)} ุณูุฏ...")
    
    # ุฒูุงูโุณูุฌ ุงูุฒูุฏู ุงุณูุงุฏ
    start_time = time.time()
    result = engine.add_documents(large_docs, large_meta, batch_size=50)
    add_time = time.time() - start_time
    
    print(f"โฑ๏ธ  ุฒูุงู ุงูุฒูุฏู ุงุณูุงุฏ: {add_time:.2f} ุซุงูู")
    print(f"๐ ุณุฑุนุช ูพุฑุฏุงุฒุด: {len(large_docs)/add_time:.1f} ุณูุฏ/ุซุงูู")
    
    # ุขุฒูุงุด ุณุฑุนุช ุฌุณุชุฌู
    test_queries = ["ููุด ูุตููุน", "machine learning", "ุงููุช", "technology", "blockchain"]
    search_times = []
    
    print("\n๐ ุขุฒูุงุด ุณุฑุนุช ุฌุณุชุฌู:")
    for query in test_queries:
        start_time = time.time()
        result = engine.search(query, top_k=10)
        search_time = time.time() - start_time
        search_times.append(search_time)
        
        print(f"   '{query}': {search_time:.3f}s ({result['returned_count']} ูุชุฌู)")
    
    avg_search_time = sum(search_times) / len(search_times)
    print(f"\n๐ ูุงูฺฏู ุฒูุงู ุฌุณุชุฌู: {avg_search_time:.3f} ุซุงูู")

def main():
    """ุชุงุจุน ุงุตู"""
    print("=" * 60)
    print("๐ ุณุณุชู ุฌุณุชุฌู ุฑูุฒูฺฏุงุฑ ููููุฑูฺฉ (FHE)")
    print("=" * 60)
    
    try:
        # ุงุณุชูุงุฏู ูพุงู
        demonstrate_basic_usage()
        
        # ูฺฺฏโูุง ูพุดุฑูุชู
        demonstrate_advanced_features()
        
        # ุขุฒูุงุด ุนููฺฉุฑุฏ
        performance_benchmark()
        
        print("\nโ ููู ุขุฒูุงุดโูุง ุจุง ููููุช ฺฉุงูู ุดุฏ!")
        print("๐ ูุงฺฏโูุง ุฏุฑ ูุงู fhe_search.log ุฐุฎุฑู ุดุฏูโุงูุฏ.")
        
    except Exception as e:
        print(f"\nโ ุฎุทุง ุฏุฑ ุงุฌุฑุง: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()